# Broker ID (ensure this is unique if you run multiple brokers)
broker.id=1

# The address of the listeners for Kafka brokers
listeners=PLAINTEXT://0.0.0.0:20001

# Advertised listeners for external clients to connect to Kafka
advertised.listeners=PLAINTEXT://localhost:20002

# Zookeeper connection details
zookeeper.connect=zookeeper:20000

# Number of partitions to distribute load. More partitions allow more parallelism
num.partitions=10  # Adjust based on your use case

# Number of replication factors for fault tolerance. Set to 3 for production.
# Replication can reduce performance due to disk I/O, so for testing, set to 1.
default.replication.factor=1  # Can be set to 3 for production environments

# Log segment settings to optimize write performance
log.segment.bytes=1073741824  # 1 GB per log segment (adjust based on disk size)
log.retention.hours=168       # 1 week retention (adjust based on your requirements)

# Enable compression for messages to reduce network and disk usage
compression.type=snappy       # snappy is a good balance between speed and compression ratio

# Batch settings to optimize message throughput. Larger batch sizes improve throughput.
# Setting a higher batch size allows more messages to be sent in a single request.
batch.size=32768              # 32 KB (adjust based on your message size and throughput)
linger.ms=5                   # 5ms delay to allow for message batching (lower for quicker delivery)

# Number of I/O threads for reading and writing messages
num.io.threads=8              # Use multiple I/O threads if possible

# Number of threads for processing messages
num.network.threads=3         # Handles network requests
num.replica.fetchers=2        # Number of fetchers for replication (increasing this improves replication throughput)

# Buffer size for network and socket connections
socket.receive.buffer.bytes=1048576   # 1 MB buffer size
socket.send.buffer.bytes=1048576      # 1 MB buffer size

# Disk write and flush performance settings
log.flush.interval.messages=10000   # Flush messages after every 10,000 messages
log.flush.interval.ms=1000          # Or flush every 1 second, whichever comes first

# Enable auto.create.topics to allow Kafka to create topics automatically
auto.create.topics.enable=true

# Memory settings for better throughput
log.retention.check.interval.ms=300000 # Log retention check every 5 minutes
